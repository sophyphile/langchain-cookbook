# Prompts - Text generally used as instructions to your model
import os
from dotenv import load_dotenv

load_dotenv()

openai_api_key = os.getenv("OPENAI_API_KEY")

# from langchain.llms import OpenAI

# llm = OpenAI(model_name="text-davinci-003", openai_api_key=openai_api_key)

# prompt = """
# Today is Monday, tomorrow is Wednesday.

# What is wrong with that statement?
# """

# print(llm(prompt))

# Prompt Template
# An object that helps creates prompts based on a combination of user input, other non-static info and a fixed template string.

# from langchain.llms import OpenAI
# from langchain import PromptTemplate

# llm = OpenAI(model_name="text-davinci-003", openai_api_key=openai_api_key)

# # Notice "location" below, that is a placeholder for another value later
# template = """
# I really want to travel to {location}. What should I do there?

# Respond in one short sentence
# """

# prompt = PromptTemplate(
#     input_variables=["location"],
#     template=template
# )

# final_prompt = prompt.format(location="Rome")

# print(f"Final Prompt: {final_prompt}")
# print("--------------")
# print(f"LLM Output: {llm(final_prompt)}")


# Example Selectors
# An easy way to select from a series of examples that allow you to dynamic place in-context information into your prompt. Often used when your task is nuanced or you have a large list of examples.

# from langchain.prompts.example_selector import SemanticSimilarityExampleSelector
# from langchain.vectorstores import FAISS
# from langchain.embeddings import OpenAIEmbeddings
# from langchain.prompts import FewShotPromptTemplate, PromptTemplate
# from langchain.llms import OpenAI

# llm = OpenAI(model_name="text-davinci-003", openai_api_key=openai_api_key)

# example_prompt = PromptTemplate(
#     input_variables = ["input", "output"],
#     template = "Example Input: {input}\nExample Output: {output}"
# )

# # Examples of locations that nouns are found
# examples = [
#     {"input": "pirate", "output": "ship"},
#     {"input": "pilot", "output": "plane"},
#     {"input": "driver", "output": "car"},
#     {"input": "tree", "output": "ground"},
#     {"input": "bird", "output": "nest"}
# ]

# # SemanticSearchExampleSelector will select examples that are similar to your input by semantic search

# example_selector = SemanticSimilarityExampleSelector.from_examples(
#     # This is the list of examples available to select from.
#     examples,

#     # This is the embedding class used to produce embeddings which are used to measure semantic similarity
#     OpenAIEmbeddings(openai_api_key=openai_api_key),

#     # This is the VectorStore class that is used to store the embeddings and do a similarity search
#     FAISS,

#     # This is the number of examples to produce.
#     k=2
# )

# similar_prompt = FewShotPromptTemplate(
#     # The object that will help select examples
#     example_selector = example_selector,

#     # Your prompt
#     example_prompt=example_prompt,

#     # Customisations that will be added to the top and bottom of your prompt
#     prefix="Give the location an item is usually found in",
#     suffix="Input: {noun}\nOutput:",

#     # What inputs your prompt will receive
#     input_variables=["noun"]
# )

# # Select a noun!
# my_noun = "student"
# print(similar_prompt.format(noun=my_noun))
# print(llm(similar_prompt.format(noun=my_noun)))

# my_noun = "flower"
# print(similar_prompt.format(noun=my_noun))
# llm(similar_prompt.format(noun=my_noun))


# Output Parsers
# A helpful way to format the output of a model. Usually used for structured output.
# Two big concepts:
# 1. Format Instructions - An autogenerated prompt that tells the LLM how to format its response based off your desired result.
# 2. Parser - A method which will extract your model's text output into a desired structure (usually JSON).

from langchain.output_parsers import StructuredOutputParser, ResponseSchema
from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, PromptTemplate
from langchain.llms import OpenAI

llm = OpenAI(model_name="text-davinci-003", openai_api_key=openai_api_key)

# How would you like your response structured? This is basically a fancy prompt template
response_schemas = [
    ResponseSchema(name="bad_string", description="This a poorly formatted user input string"),
    ResponseSchema(name="good_string", description="This is your response, a reformatted response")
]

# How you would like to parse your output
output_parser = StructuredOutputParser.from_response_schemas(response_schemas)

# See the prompt template you created for formatting
format_instructions = output_parser.get_format_instructions()
# print(format_instructions)

template = """
You will be given a poorly formatted string from a  user. 
Reformat it and make sure all the words are spelled correctly

{format_instructions}

% USER INPUT:
{user_input}

YOUR RESPONSE:
"""

prompt = PromptTemplate(
    input_variables=["user_input"],
    partial_variables={"format_instructions": format_instructions},
    template=template
)

promptValue = prompt.format(user_input="welcom 2 califonyyyyya!")
# print(promptValue)

llm_output = llm(promptValue)
print(output_parser.parse(llm_output))

